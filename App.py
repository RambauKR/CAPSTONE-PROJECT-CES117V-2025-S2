from flask import Flask, Response, render_template, redirect, url_for

import cv2  # OpenCV for webcam access and image processing
from ultralytics import YOLO
#model = YOLO('yolov8n.pt')  # load the YOLOv8 nano model pre-trained on COCO
model = YOLO('best.pt')  # load your blood cell YOLOv8 model (replace 'best.pt' with your filename if different)

app = Flask(__name__)

# Initialize webcam video capture (0 for default camera)
cap = cv2.VideoCapture(1)
if not cap.isOpened():
    raise RuntimeError("Could not access webcam.")

# Global variables for snapshot/record functionality
last_frame = None        # to store the last frame for snapshot
recording = False        # flag to indicate if recording is on
video_writer = None      # VideoWriter object for recording



def generate_frames():
    global cap, last_frame, recording, video_writer
    while True:
        success, frame = cap.read()
        if not success:
            break

        # (Optional) You could still apply thresholding here if needed:
        # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        # _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)
        # ... (We won't use 'thresh' for final output when YOLO is enabled)

        # **YOLOv8: Object Detection on the frame**
        results = model.predict(frame, conf=0.5)  # run YOLO inference with 50% confidence threshold
        # The results object may contain predictions for one or more images; we have one image (frame)
        # Draw bounding boxes and labels on the frame
        annotated_frame = results[0].plot()  # Ultralytics provides a .plot() method to draw results on image

        # Update last_frame for snapshot (already in BGR with annotations)
        last_frame = annotated_frame.copy()

        # Write to video if recording
        if recording and video_writer:
            video_writer.write(annotated_frame)

        # Encode and yield the annotated frame
        ret, buffer = cv2.imencode('.jpg', annotated_frame)
        if not ret:
            continue
        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

        

# Route to stream the video feed
@app.route('/video_feed')
def video_feed():
    # Return a multipart response generated by the frame generator
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

# Route for the homepage
@app.route('/')
def index():
    # Render an HTML template that shows the video stream and controls
    return render_template('index.html')

@app.route('/snapshot')
def snapshot():
    global last_frame
    if last_frame is None:
        return "No frame available to capture", 400
    # Save the last frame to a file in the static directory
    cv2.imwrite('static/snapshot.jpg', last_frame)
    # Redirect to the saved image so the user can see/download it
    return redirect(url_for('static', filename='snapshot.jpg'))

@app.route('/toggle_record')
def toggle_record():
    global recording, video_writer
    if not recording:
        # Start recording: initialize VideoWriter to save video
        fourcc = cv2.VideoWriter_fourcc(*'XVID')  # choose codec (XVID for .avi)
        # Assuming 640x480 resolution and 20 FPS
        video_writer = cv2.VideoWriter('static/output.avi', fourcc, 20.0, (640, 480))
        recording = True
        # Redirect back to index with a flag to indicate recording state
        return redirect(url_for('index', rec=1))
    else:
        # Stop recording: release the VideoWriter
        recording = False
        if video_writer:
            video_writer.release()
            video_writer = None
        return redirect(url_for('index'))

if __name__ == '__main__':
    app.run(debug=True)




